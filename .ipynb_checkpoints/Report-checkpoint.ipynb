{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4de9f1c-3176-46a2-92b2-32a05e9e6011",
   "metadata": {},
   "source": [
    "# Prepare IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de48d78-a744-4638-b5a4-39c094528911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install numpy scikit-learn tensorflow\n",
    "!python prepare.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f792517-cee5-4fb3-96b2-459039dca166",
   "metadata": {},
   "source": [
    "# Collect Knowledge for IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0bb902-6e51-4a55-aa72-85a648303522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/cair/tmu.git\n",
    "!python collect.py\n",
    "# or import the IMDbKnowledge folder content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1554bb-89cb-4640-bc29-c016b162b879",
   "metadata": {},
   "source": [
    "# Text Augmentation using EDA and Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "365c3d0f-b848-416d-97ae-2e861bb8536b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmedkk/DAT945/eda.py:214: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  words = [word for word in words if word is not '']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original word: mood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator CountVectorizer from version 1.4.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original word: danger\n",
      "original word: foresightful\n",
      "original word: increase\n",
      "original word: radiation syndrome\n",
      "original word: ensnare\n",
      "original word: important\n",
      "original word: contemporaries\n",
      "original word: crest\n",
      "original word: case\n",
      "original word: lifetime\n",
      "original word: let in\n",
      "original word: part\n",
      "original word: activity\n",
      "original word: stimulate\n",
      "original word: admit\n",
      "original word: subjugate\n",
      "original word: fire\n",
      "original word: end\n",
      "original word: involve\n",
      "original word: low down\n",
      "original word: applied science\n",
      "original word: give\n",
      "original word: ingestion\n",
      "original word: keep down\n",
      "original word: contraption\n",
      "original word: sentience\n",
      "original word: recitation\n",
      "original word: rigorousness\n",
      "original word: drouth\n",
      "original word: clime\n",
      "original word: belittled\n",
      "original word: corporate\n",
      "original word: variety\n",
      "original word: modification\n",
      "original word: cause\n",
      "original word: consignment\n"
     ]
    }
   ],
   "source": [
    "from eda import *\n",
    "\n",
    "num_aug = 1\n",
    "alpha_sr = 0.1\n",
    "alpha_ri = 0\n",
    "alpha_rs = 0\n",
    "alpha_rd = 0 \n",
    "lines = \"\"\n",
    "\n",
    "file_path = 'input_text.txt'\n",
    "output_file_path = 'output_text.txt'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    text = file.read()\n",
    "sentences = text.split('. ')\n",
    "aug_text = '' \n",
    "for sentence in sentences:\n",
    "    aug_sentences = eda(sentence, alpha_sr=alpha_sr, alpha_ri=alpha_ri, alpha_rs=alpha_rs, p_rd=alpha_rd, num_aug=num_aug)\n",
    "    for aug_sentence in aug_sentences:\n",
    "        aug_text = aug_text + ' ' + aug_sentence + '.'\n",
    "\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(aug_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af35ad5c-305b-449c-9660-d30cf85e231e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
